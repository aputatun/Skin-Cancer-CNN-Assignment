{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aputatun/BoomBikesAssignment/blob/main/Starter_code_Assignment_CNN_Skin_Cancer_(1)_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvR7ppk77v31"
      },
      "source": [
        "### Importing Skin Cancer Data\n",
        "#### To do: Take necessary actions to read the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "### Importing all the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "IxHLggyCPV8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpVPmT5z7AP"
      },
      "source": [
        "## If you are using the data by mounting the google drive, use the following :\n",
        "## from google.colab import drive\n",
        "## drive.mount('/content/gdrive')\n",
        "\n",
        "##Ref:https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpUsRQwOOL72"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "source": [
        "# Defining the path for train and test images\n",
        "## Todo: Update the paths of the train and test dataset\n",
        "data_dir_train = pathlib.Path(r\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "data_dir_test = pathlib.Path(r\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(r\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Test\")\n"
      ],
      "metadata": {
        "id": "7BL5vuVFSuap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqksN1w5Fu-N"
      },
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8HkfW3jPJun"
      },
      "source": [
        "### Load using keras.preprocessing\n",
        "\n",
        "Let's load these images off disk using the helpful image_dataset_from_directory utility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "### Create a dataset\n",
        "\n",
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "validation_split = 0.2\n",
        "shuffle=True\n",
        "seed= 123\n",
        "label_mode = 'categorical'\n",
        "labels = 'inferred'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "source": [
        "## Write your train dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "train_ds  = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=data_dir_train,\n",
        "    seed=seed,\n",
        "    shuffle=shuffle,\n",
        "    validation_split=validation_split,\n",
        "    subset=\"training\",\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode = label_mode\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "source": [
        "## Write your validation dataset here\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "val_ds =  tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=data_dir_train,\n",
        "    seed=seed,\n",
        "    shuffle=shuffle,\n",
        "    validation_split=validation_split,\n",
        "    subset=\"validation\",\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode = label_mode\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "source": [
        "# List out all the classes of skin cancer and store them in a list.\n",
        "# You can find the class names in the class_names attribute on these datasets.\n",
        "# These correspond to the directory names in alphabetical order.\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsm5oYiQH_b"
      },
      "source": [
        "### Visualize the data\n",
        "#### Create a code to visualize one instance of all the nine classes present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKILZ48I-q1k"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_images = {class_name: None for class_name in class_names}\n",
        "\n",
        "def get_image_of_class(dataset, target_class, class_names):\n",
        "    for images, labels in dataset:\n",
        "        for image, label in zip(images, labels):\n",
        "            label_index = label.numpy().argmax() # Get the index of the class with highest probability\n",
        "\n",
        "            class_name = class_names[label_index] # Index class_names with the integer index\n",
        "\n",
        "            if class_name == target_class:\n",
        "              class_images[target_class] = image\n",
        "              return None\n",
        "    return None\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "# Specify the target class\n",
        "for i in class_names:\n",
        "  target_class = i\n",
        "\n",
        "  # Get an image of the specified class\n",
        "  image = get_image_of_class(train_ds, target_class, class_names)\n",
        "\n",
        "  # Plot the image if found\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i, (class_name, image) in enumerate(class_images.items()):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(class_name)\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzVXBHiyQ7_I"
      },
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wZlKRBEGNtU"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "### Create the model\n",
        "#### Created a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "## Todo add preprocessing layer to the model.\n",
        "input_shape = (img_height,img_width,3)\n",
        "\n",
        "model = Sequential()    #Sequential allows you to create models layer-by-layer\n",
        "\n",
        "#First Convulation Layer\n",
        "model.add(layers.Rescaling(1./255,input_shape=input_shape))\n",
        "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(layers.Flatten())   #Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
        "\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Dense Layer\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dense Layer with softmax activation function.\n",
        "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
        "model.add(layers.Dense(len(class_names),activation='softmax'))"
      ],
      "metadata": {
        "id": "fot8_kwUv03b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pydjgqe1u8T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRnKRxf0rKGS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "### Compile the model\n",
        "Choose an appropirate optimiser and loss function for model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8wKtiPGe1j"
      },
      "source": [
        "### Todo, choose an appropirate optimiser and loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZGWN4MZGhtJ"
      },
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds"
      ],
      "metadata": {
        "id": "q8skYYZRnszC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "id": "GWZbyfPxlHvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-kO2MB2yprgC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPphJYuSZhK"
      },
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRTPbJEn-pX"
      },
      "source": [
        "#### With Training accuracy of around 90% and validation accuracy of 54% there is a clear sign of the overfitting of the model.\n",
        "#### The Training vs. Validation accuracy graph shows that as the number of epochs increases, the gap between training accuracy and validation accuracy widens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22hljAl6GykA"
      },
      "source": [
        "# After analysing the model fit history there is presence of overfitting the model\n",
        "# We will use the below augmentation technique\n",
        "\n",
        "rescale = tf.keras.Sequential([\n",
        "  #To rescale an input in the [0, 255] range to be in the [0, 1] range\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  #Randomly flip each image horizontally and vertically.\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "\n",
        "  #Randomly rotate each image.\n",
        "  layers.RandomRotation(0.2),\n",
        "\n",
        "  #Randomly zoom each image during training.\n",
        "  layers.RandomZoom(0.2),\n",
        "\n",
        "  #Randomly translate each image during training.\n",
        "  layers.RandomTranslation(0.1, 0.1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEjPWh8GG0C7"
      },
      "source": [
        "# Todo, visualize how your augmentation strategy works for one instance of training image.\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      },
      "source": [
        "### Todo:\n",
        "### Create the model, compile and train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3V4l-O9G3dM"
      },
      "source": [
        "## You can use Dropout layer if there is an evidence of overfitting in your findings\n",
        "\n",
        "## Your code goes here\n",
        "model2 = Sequential()                     #Sequential allows you to create models layer-by-layer\n",
        "\n",
        "model2.add(data_augmentation)             #Augmentation layer\n",
        "model2.add(rescale)                       #Rescaling layer\n",
        "\n",
        "#First Convulation Layer\n",
        "model2.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "#Second Convulation Layer\n",
        "model2.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "#Third Convulation Layer\n",
        "model2.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
        "model2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
        "model2.add(layers.Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "model2.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Dense Layer\n",
        "model2.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dropout layer with 50% Fraction of the input units to drop.\n",
        "model2.add(layers.Dropout(0.50))\n",
        "\n",
        "#Dense Layer with softmax activation function.\n",
        "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
        "model2.add(layers.Dense(len(class_names),activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUWFp96UIAN"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7yTm8IG8zR"
      },
      "source": [
        "## Your code goes here\n",
        "model2.compile(optimizer='Adam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Zhcjgsbr0LZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC-D_RWOURp6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcPfkUASHBf9"
      },
      "source": [
        "## Your code goes here, note: train your model for 20 epochs\n",
        "epochs =20\n",
        "history = model2.fit(train_ds,epochs=epochs,validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      },
      "source": [
        "### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjN_F4QxHIsh"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      },
      "source": [
        "- #### Applying data augmentation and a dropout layer has reduced the overfitting issue.\n",
        "- #### The model's performance has not significantly improved. Training Accuracy has decreased by almost half. Next, I will examine the class distribution in the training set to check for any class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      },
      "source": [
        "#### **Todo:** Find the distribution of classes in the training dataset.\n",
        "#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhwYgtTQRzq"
      },
      "source": [
        "## Your code goes here.\n",
        "def class_distribution_count(directory):\n",
        "\n",
        "    #count number of image in each classes\n",
        "    count= []\n",
        "    for path in pathlib.Path(directory).iterdir():\n",
        "        if path.is_dir():\n",
        "            count.append(len([name for name in os.listdir(path)\n",
        "                               if os.path.isfile(os.path.join(path, name))]))\n",
        "\n",
        "    #name of the classes\n",
        "    sub_directory = [name for name in os.listdir(directory)\n",
        "                    if os.path.isdir(os.path.join(directory, name))]\n",
        "\n",
        "    #return dataframe with image count and class.\n",
        "    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n",
        "\n",
        "df = class_distribution_count(data_dir_train)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csQL1dvO0b2"
      },
      "source": [
        "#### **Todo:** Write your findings here:\n",
        "#### - Which class has the least number of samples?\n",
        "    seborrheic keratosis has the least number of samples only 77.\n",
        "#### - Which classes dominate the data in terms proportionate number of samples?\n",
        "pigmented benign keratosis (462 Samples), melanoma (438 Samples), basal cell carcinoma (376 Samples), and nevus (357 Samples) classes dominates the data in terms proportionate number of samples ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      },
      "source": [
        "#### Rectify the class imbalance\n",
        "#### **Context:** You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItAg4rU-SzJh"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      },
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipeline’s` `sample()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Egt9EHjR-Dd"
      },
      "source": [
        "path_to_training_dataset = pathlib.Path(r\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset / i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWcMqZhdRWz"
      },
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tODrYIY2nxJ"
      },
      "source": [
        "import glob\n",
        "path_list = [x for x in glob.glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "path_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvVdF7g3E1z"
      },
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob.glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "lesion_list_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "source": [
        "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njzBxTNT2nxK"
      },
      "source": [
        "original_df = pd.DataFrame(columns=['Path', 'Label'])  # Create an empty DataFrame with the same columns\n",
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = pd.concat([original_df, df2], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j45rmxd2nxK"
      },
      "source": [
        "new_df['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NirFBvGPmgI"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnspeMbRWNs"
      },
      "source": [
        "####  Train the model on the data created using Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcj1XgndRWz"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0haOU11Ey8ey"
      },
      "source": [
        "#### **Todo:** Create a training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ZY11judRWz"
      },
      "source": [
        "data_dir_train= pathlib.Path(r\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"training\",\n",
        "  label_mode='categorical',\n",
        "  ## Todo choose the correct parameter value, so that only training data is refered to,,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      },
      "source": [
        "#### **Todo:** Create a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX191d_3dRW0"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"validation\",## Todo choose the correct parameter value, so that only validation data is refered to,\n",
        "  label_mode='categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      },
      "source": [
        "#### **Todo:** Create your model (make sure to include normalization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch0MuKvFVr7O"
      },
      "source": [
        "## your code goes here\n",
        "model3 = Sequential()\n",
        "\n",
        "model3.add(rescale)   #Rescaling Layer\n",
        "\n",
        "#First Convulation layer\n",
        "model3.add(layers.Conv2D(32,kernel_size=(2,2),activation='relu'))\n",
        "model3.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model3.add(layers.Dropout(0.25))\n",
        "\n",
        "#Second Convulation Layer\n",
        "model3.add(layers.Conv2D(64,kernel_size=(2,2),activation='relu'))\n",
        "model3.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "model3.add(layers.Dropout(0.25))\n",
        "\n",
        "#Third Convulation Layer\n",
        "model3.add(layers.Conv2D(128,kernel_size=(2,2),activation='relu'))\n",
        "model3.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatten Layer\n",
        "model3.add(layers.Flatten())\n",
        "\n",
        "#Dense Layer\n",
        "model3.add(layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Dropout layer\n",
        "model3.add(layers.Dropout(0.25))\n",
        "\n",
        "#Batch normalization: is a method used to make artificial neural networks faster and more stable through normalization\n",
        "#of the layers' inputs by re-centering and re-scaling.\n",
        "model3.add(layers.BatchNormalization())\n",
        "\n",
        "#Dense Layer\n",
        "model3.add(layers.Dense(128,activation='relu'))\n",
        "\n",
        "#Dropout layer with 50% Fraction of the input units to drop.\n",
        "model3.add(layers.Dropout(0.50))\n",
        "\n",
        "#Batch normalization\n",
        "model3.add(layers.BatchNormalization())\n",
        "\n",
        "#Dense layer with Softmax activation function.\n",
        "model3.add(layers.Dense(len(class_names),activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      },
      "source": [
        "#### **Todo:** Compile your model (Choose optimizer and loss function appropriately)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47GWmLbdRW1"
      },
      "source": [
        "## your code goes here\n",
        "model3.compile(optimizer='adam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      },
      "source": [
        "#### **Todo:**  Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcV6OdI4dRW1"
      },
      "source": [
        "epochs = 50\n",
        "history = model3.fit(train_ds,epochs=epochs,validation_data=val_ds,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      },
      "source": [
        "  Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCTXwfkTdRW1"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way4lakC4_p0"
      },
      "source": [
        "- In the final model (Model 3), both training and validation accuracy improved.\n",
        "- The overfitting problem has been resolved.\n",
        "- Rebalancing the classes through augmentation contributed to achieving the best training and validation accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV2BHg1dWrdY"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "data_dir_test =  pathlib.Path(r\"/content/gdrive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Test\")\n",
        "Test_image_path = os.path.join(data_dir_test, class_names[1], '*')\n",
        "Test_image = glob.glob(Test_image_path)\n",
        "Test_image = load_img(Test_image[-1],target_size=(180,180,3))\n",
        "plt.imshow(Test_image)\n",
        "plt.grid(False)\n",
        "\n",
        "img = np.expand_dims(Test_image,axis=0)\n",
        "pred = model.predict(img)\n",
        "pred = np.argmax(pred)\n",
        "pred_class = class_names[pred]\n",
        "print(\"Actual Class \"+ class_names[1] +'\\n'+ \"Predictive Class \"+pred_class )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}